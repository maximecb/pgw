<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>The End of Online Anonymity</title>
  <link rel="stylesheet" href="../../../../style.css">
  <link rel="alternate" type="application/rss+xml" title="Pointers Gone Wild RSS Feed" href="/rss.xml">
  <link rel="icon" type="image/svg+xml" href="/favicon.svg">

  <!-- Social media card -->
  <meta property="og:type" content="article">
  <meta property="og:title" content="The End of Online Anonymity">
  <meta property="og:description" content="The End of Online Anonymity">
  
  <meta name="twitter:card" content="summary_large_image">
</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-DC24K385F8"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-DC24K385F8');
</script>

<script>
document.addEventListener('keydown', (e) => {
    let ctrlDown = e.ctrlKey || e.metaKey;

    // Ctrl + C
    if (ctrlDown && e.key.toUpperCase() === 'C') {
        if (window.getSelection().toString().length == 0) {
            navigator.clipboard.writeText("open site/2019-06-10-the-end-of-online-anonymity/index.md");
        }
    }

    // Shift + left arrow
    if (e.shiftKey && event.keyCode === 37) {
        window.location.href = "../../../../2019/01/29/miniworld-a-vizdoom-alternative-for-openai-gym/";
    }

    // Shift + right arrow
    if (e.shiftKey && event.keyCode === 39) {
        window.location.href = "../../../../2019/10/06/zupiter-a-web-based-modular-synthesizer/";
    }
});
</script>

<body>
<div class="container">

<div class="top_bar">
  <div class="pgw">
    <a href="../../../..">Pointers Gone Wild</a>
  </div>
  <nav>
    <a href="../../../../about/">About</a>
    <a href="https://github.com/maximecb">GitHub</a>
    <a href="https://x.com/love2code">x.com</a>

    <!--
    <a href="../../../../about/">About</a>
    <a href="../../../../about/">Projects</a>
    <a href="https://github.com/maximecb"><img style="width: 1.2rem;" src="/github_icon.svg" alt="GitHub account"/></a>
    <a href="https://x.com/love2code"><img style="width: 1.2rem;" src="/x_icon.svg" alt="x.com account"/></a>
    <a href="/feed.xml"><img style="width: 1.2rem;" src="/rss_icon.svg" alt="RSS feed"/></a>
    -->
  </nav>
</div>

<div class="contents">
<div class="page_title">
<h1>The End of Online Anonymity</h1>
<div class="post_date">June 10th, 2019</div>
</div>
<p>Since 2015, I've been writing about the impact that machine learning will have on our society. One of the most concerning possibilities, in my mind, was always the <a href="/2015/09/12/why-you-should-be-a-little-scared-of-machine-learning/">potential abuse</a> of these technologies by malicious actors to manipulate or scam people, either through subtle means or by impersonating those they trust.</p>
<p>Today, this concern is very much mainstream: "fake news" has become a buzzword and a kind of modern-day boogeyman. For the most part, I think most people aren't overly worried. We know that there <a href="https://www.youtube.com/watch?v=1PGm8LslEb4">already are</a> malicious actors creating sketchy content and putting it out there, but most of it seems obviously fake if you examine it more closely. We all assume that we will always be smart enough to tell real from fake, and carry on.</p>
<p>Media manipulation is nothing new. Attempts to control public discourse and influence the masses predate the internet, TV, newspapers and the printing press. What's about to change is that now, with machine learning, it will become possible to turn electricity into millions of voices relentlessly spreading your gospel to every corner of the internet. At this point in time, it seems most of the fake content out there is not generated using machine learning, it's created by human beings using puppet accounts. For the most part, someone still has to turn the crank. That limits how much content can be created and how many sources it can come from.</p>
<p>Personally, I'm not just worried about manipulative articles being passed as news. I'm also worried about the impact that networks of malicious bots will have on online communities. We're still fairly far from being at the point where we can automatically generate news articles that appear convincing upon close inspection, but what about online comment threads? How difficult is it to build a bot that can write convincing one or two sentences comments?</p>
<p>Yesterday, I stumbled upon a link to <a href="https://www.reddit.com/r/SubSimulatorGPT2/">a subreddit</a> populated by bots based on <a href="https://openai.com/blog/better-language-models/">OpenAIs GPT-2</a> text generation model. The result is certainly funny, but also leaves me feeling uncomfortable. Yes, much of the content is obviously fake, but many of the comments are actually believable. If you feel unimpressed, you should keep in mind that this is an individual's side project that repurposed an existing neural network. As it is, the GPT-2 model simply generates text and completes a sentence. It's an impressive and amusing tech demo, but not something you can easily control. In order to weaponize GPT-2, a malicious actor would need to add some kind of a guidance system: a way to condition text output of the model so as to spread a specific message.</p>
<p>The solution to the fake content problem may seem obvious: we can fight fire with fire, and build machine learning tools to detect machine-generated content. Tools like this are already in the works. Grover boasts 92% accuracy in detecting fake content. The sad reality, however, is that this is an arms race, and it's not clear at all that this is something we can win. As technology improves, fake content will become harder and harder to tell apart from real content. Manual content verification won't be able to keep up with the volume, and automated filtering systems will fail.</p>
<p>In my opinion, there is only one effective way to stop fake content, and this is to verify that everyone who posts content is in fact human. You could ask people to upload pictures of themselves, but we're already at the point where we can produce <a href="https://www.youtube.com/watch?v=XOxxPcy5Gr4">realistic images of imaginary people</a> using GANs. Any counter-measure of this form will inevitably be defeated. Ultimately, an unfortunate possibility is that online platforms will begin requiring a verified government ID in order to register. We could even end up living in a dystopian world where a kind of "e-passport", crypto-signed government ID is attached to your every internet connection, and tracked everywhere online, which is very sad to think about.</p>
<p>The rise of bots could render many online communities simply uninhabitable. Large social media websites may have some hope of policing content, but smaller independent players likely won't have the resources. We are moving towards a model where the internet is dominated by a few centralized content providers and their walled gardens, and generated content may unfortunately make it even harder for grassroots online communities to survive and grow.</p>
<p>I don't want to see online anonymity be taken away. I hope there is a way to build a new web, a new kind of social media using a hash graph to implement a decentralized web of trust, something that can allow content verification without forcing everyone to sacrifice their right to remain anonymous online. I certainly think it's a problem that's worth thinking about and I hope to see more research in that direction, because unless we can come up with a technological solution, a regulatory solution may be imposed onto us, and it will inevitably favor the big players at the expense of the small.</p>
<p><b>EDIT 2022-02-06: I want to make it crystal clear that I am advocating against centralized online IDs, not in favor of them. This post is meant to read as a warning, not an endorsement.</b></p>
<div class="copyright">
    Copyright &copy; 2011&ndash;2025 Maxime Chevalier-Boisvert. All rights reserved.
</div>

</div> <!-- contents -->
</div> <!-- container -->

</body>
</html>
